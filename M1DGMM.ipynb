{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M1DGMM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w6o0iNJt764"
      },
      "source": [
        "# M1DGMM code lauching to reproduce the results of the experiment in the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC6wn2rluL8V"
      },
      "source": [
        "This notebook presents the data preprocessing used in the paper to benchmark the M1DGMM performance. It is actually a synthesis of the scripts contained in the files named \"test_on_\\<dataset_name.py\\>\" in the M1DGMM repository. \r\n",
        "The other models can be run in much the same way using the \"test_on_\\<dataset_name.py\\>\" files of the other repositories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVlsDwbbvJVj",
        "outputId": "0d58521f-2fe9-4926-fe2f-205ab286a4d2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6iV4O0NwTNq",
        "outputId": "f0f966da-10d6-415e-d095-dc247aee9650"
      },
      "source": [
        "%cd gdrive/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvCT2AQjwYGc",
        "outputId": "ccc1c885-db7f-48e2-8425-d5c0843d8046"
      },
      "source": [
        "%cd My Drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AINfRV5PweiC",
        "outputId": "d2046b0f-5493-49d9-bb4e-3ff53779445b"
      },
      "source": [
        "%cd MDGMM_suite"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/MDGMM_suite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPVW8oBBvKNr"
      },
      "source": [
        "! git clone https://github.com/RobeeF/M1DGMM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvQAHGw-w_pU",
        "outputId": "e73d3b72-6ad1-4b85-fa5a-1a3c604e8866"
      },
      "source": [
        "!pip install gower"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gower\n",
            "  Downloading https://files.pythonhosted.org/packages/98/62/dea557ca74253ff35afa6dce17c6f950ff8b7fbd3636a4df2ef0877bcf65/gower-0.0.5.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gower) (1.19.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gower) (1.4.1)\n",
            "Building wheels for collected packages: gower\n",
            "  Building wheel for gower (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gower: filename=gower-0.0.5-cp36-none-any.whl size=4233 sha256=b262ca9c00e47f4f66f2b237dc440fb65f87750218a36dbaf0623620a5d25ca7\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/09/9b/072d54d6ced0f43a179852e3f09532d0131e25ff7cb4e5ee75\n",
            "Successfully built gower\n",
            "Installing collected packages: gower\n",
            "Successfully installed gower-0.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNYuONKGx2QF",
        "outputId": "f5b1ed75-3011-4014-b9e1-c1d1ba545211"
      },
      "source": [
        "!pip install factor-analyzer"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting factor-analyzer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/b5/cbd83484ca6dd4c6562c6d66a6a3a0ecf526e79b2b575b9fb4bf5ad172dd/factor_analyzer-0.3.2.tar.gz (40kB)\n",
            "\r\u001b[K     |████████▏                       | 10kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 20kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 30kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from factor-analyzer) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from factor-analyzer) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from factor-analyzer) (1.19.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from factor-analyzer) (0.22.2.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->factor-analyzer) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->factor-analyzer) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->factor-analyzer) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->factor-analyzer) (1.15.0)\n",
            "Building wheels for collected packages: factor-analyzer\n",
            "  Building wheel for factor-analyzer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for factor-analyzer: filename=factor_analyzer-0.3.2-cp36-none-any.whl size=40380 sha256=f9c8838f85bcf3999922b7a44e97a6ad3b05ef91cc0b7fb9914bc1652d3a9746\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/d0/57/f1330cb9c80e82d8d05391c74c94ed61ce3f03bf6157f3d6db\n",
            "Successfully built factor-analyzer\n",
            "Installing collected packages: factor-analyzer\n",
            "Successfully installed factor-analyzer-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcfSa5AXx6Pt",
        "outputId": "e78652e0-ad9c-401b-eff2-6f63d8ef5e74"
      },
      "source": [
        "!pip install prince"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting prince\n",
            "  Downloading https://files.pythonhosted.org/packages/94/6c/491a3fabfd1ce75e285a4fe4200fccde5d83664733541a3a74c0b02e77fb/prince-0.7.1-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from prince) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17.1 in /usr/local/lib/python3.6/dist-packages (from prince) (1.19.4)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from prince) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from prince) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.6/dist-packages (from prince) (0.22.2.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.3->prince) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.3->prince) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.2->prince) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.2->prince) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.2->prince) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.1->prince) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.3->prince) (1.15.0)\n",
            "Installing collected packages: prince\n",
            "Successfully installed prince-0.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZIvMXGdyGgF",
        "outputId": "a0bf5b7e-edf4-4444-ec84-3f66485a3689"
      },
      "source": [
        "!pip install numdifftools"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numdifftools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/c0/b0d967160ecc8db52ae34e063937d85e8d386f140ad4826aae2086245a5e/numdifftools-0.9.39-py2.py3-none-any.whl (953kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 5.4MB/s \n",
            "\u001b[?25hInstalling collected packages: numdifftools\n",
            "Successfully installed numdifftools-0.9.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5iwX0ge2WYzG",
        "outputId": "ad151026-74f2-422d-f088-421ebc13efcb"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/MDGMM_suite'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCr9YEhTjaSY"
      },
      "source": [
        "import os \r\n",
        "\r\n",
        "os.chdir('/content/gdrive/My Drive/MDGMM_suite/M1DGMM')\r\n",
        "\r\n",
        "from copy import deepcopy\r\n",
        "\r\n",
        "from sklearn.metrics import precision_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.preprocessing import LabelEncoder \r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "\r\n",
        "from gower import gower_matrix\r\n",
        "from sklearn.metrics import silhouette_score\r\n",
        "\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from m1dgmm import M1DGMM\r\n",
        "from init_params import dim_reduce_init\r\n",
        "from metrics import misc, cluster_purity\r\n",
        "from data_preprocessing import gen_categ_as_bin_dataset, \\\r\n",
        "        compute_nj\r\n",
        "\r\n",
        "import autograd.numpy as np\r\n",
        "from numpy.random import uniform\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiAO2nFFDWNx"
      },
      "source": [
        "# M1GMM benchmarking on Australian Credit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK-Y4J_D-UhE"
      },
      "source": [
        "###############################################################################\n",
        "################################ Credit data    ###############################\n",
        "###############################################################################\n",
        "\n",
        "#===========================================#\n",
        "# Importing data\n",
        "#===========================================#\n",
        "os.chdir('/content/gdrive/My Drive/MDGMM_suite/datasets')\n",
        "\n",
        "credit = pd.read_csv('australian_credit/australian.csv', sep = ' ', header = None)\n",
        "y = credit.iloc[:,:-1]\n",
        "labels = credit.iloc[:,-1]\n",
        "\n",
        "y = y.infer_objects()\n",
        "numobs = len(y)\n",
        "\n",
        "\n",
        "n_clusters = len(np.unique(labels))\n",
        "p = y.shape[1]\n",
        "\n",
        "#===========================================#\n",
        "# Formating the data\n",
        "#===========================================#\n",
        "var_distrib = np.array(['bernoulli', 'continuous', 'continuous', 'categorical',\\\n",
        "                        'categorical', 'categorical', 'continuous', 'bernoulli',\\\n",
        "                        'bernoulli', 'continuous', 'bernoulli', 'categorical',\\\n",
        "                        'continuous', 'continuous']) \n",
        " \n",
        "# No ordinal data \n",
        " \n",
        "y_categ_non_enc = deepcopy(y)\n",
        "vd_categ_non_enc = deepcopy(var_distrib)\n",
        "\n",
        "# Encode categorical datas\n",
        "# Test to encode categorical variables\n",
        "le = LabelEncoder()\n",
        "for col_idx, colname in enumerate(y.columns):\n",
        "    if var_distrib[col_idx] == 'categorical': \n",
        "        y[colname] = le.fit_transform(y[colname])\n",
        "\n",
        "# No binary data \n",
        "\n",
        "enc = OneHotEncoder(sparse = False, drop = 'first')\n",
        "labels_oh = enc.fit_transform(np.array(labels).reshape(-1,1)).flatten()\n",
        "\n",
        "nj, nj_bin, nj_ord, nj_categ = compute_nj(y, var_distrib)\n",
        "y_np = y.values\n",
        "nb_cont = np.sum(var_distrib == 'continuous')\n",
        "\n",
        "p_new = y.shape[1]\n",
        "\n",
        "# Feature category (cf)\n",
        "cf_non_enc = np.logical_or(vd_categ_non_enc == 'categorical', vd_categ_non_enc == 'bernoulli')\n",
        "\n",
        "# Non encoded version of the dataset:\n",
        "y_nenc_typed = y_categ_non_enc.astype(np.object)\n",
        "y_np_nenc = y_nenc_typed.values\n",
        "\n",
        "# Defining distances over the non encoded features\n",
        "dm = gower_matrix(y_nenc_typed, cat_features = cf_non_enc) \n",
        "\n",
        "dtype = {y.columns[j]: np.float64 if (var_distrib[j] != 'bernoulli') and \\\n",
        "        (var_distrib[j] != 'categorical') else np.str for j in range(p_new)}\n",
        "\n",
        "y = y.astype(dtype, copy=True)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV84G9xDyNXi"
      },
      "source": [
        "import matplotlib as mpl\n",
        "\n",
        "backend_ =  mpl.get_backend() \n",
        "mpl.use(\"Agg\")  # Prevents from showing the plots to gain space\n",
        "\n",
        "# First: automatically find the best architecture\n",
        "r = np.array([5, 4, 3])\n",
        "numobs = len(y)\n",
        "k = [4, n_clusters]\n",
        "eps = 1E-05\n",
        "it = 3\n",
        "maxstep = 100\n",
        "\n",
        "prince_init = dim_reduce_init(y, n_clusters, k, r, nj, var_distrib, seed = None, use_famd = True)\n",
        "out = M1DGMM(y_np, n_clusters, r, k, prince_init, var_distrib, nj, it, eps, maxstep, seed = None)\n",
        "\n",
        "\n",
        "# Then run the best architecture 30 times\n",
        "\n",
        "r = out['best_r']\n",
        "numobs = len(y)\n",
        "k = out['best_k']\n",
        "eps = 1E-05\n",
        "it = 30\n",
        "maxstep = 100\n",
        "\n",
        "nb_trials= 30\n",
        "m1dgmm_res = pd.DataFrame(columns = ['it_id', 'micro', 'macro', 'silhouette'])\n",
        "\n",
        "for i in range(nb_trials):\n",
        "    prince_init = dim_reduce_init(y, n_clusters, k, r, nj, var_distrib, seed = None,\\\n",
        "                                  use_famd = True)\n",
        "\n",
        "    out = M1DGMM(y_np, n_clusters, r, k, prince_init, var_distrib, nj, it,\\\n",
        "                  eps, maxstep, seed = None, perform_selec = False)\n",
        "    m, pred = misc(labels_oh, out['classes'], True) \n",
        "    plt.close()\n",
        "\n",
        "    sil = silhouette_score(dm, pred, metric = 'precomputed')\n",
        "    micro = precision_score(labels_oh, pred, average = 'micro')\n",
        "    macro = precision_score(labels_oh, pred, average = 'macro')\n",
        "\n",
        "    m1dgmm_res = m1dgmm_res.append({'it_id': i + 1, 'micro': micro, 'macro': macro, \\\n",
        "                                'silhouette': sil}, ignore_index=True)\n",
        "\n",
        "  \n",
        "mpl.use(backend_) # Reset backend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHAY2h3IcJBw",
        "outputId": "cf53a09d-8d5f-4c2f-dfca-9d746bcfab18"
      },
      "source": [
        "print(m1dgmm_res.mean())\r\n",
        "print(m1dgmm_res.std())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it_id         15.500000\n",
            "micro          0.698696\n",
            "macro          0.802738\n",
            "silhouette     0.176574\n",
            "dtype: float64\n",
            "it_id         8.803408\n",
            "micro         0.117355\n",
            "macro         0.045442\n",
            "silhouette    0.029559\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95PWc8ViENyi"
      },
      "source": [
        "# Heart dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg_EcBwfXnRp",
        "outputId": "3afc0855-ecaa-47c2-b1f2-3e3f00d3433c"
      },
      "source": [
        "%cd ../datasets"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/MDGMM_suite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDLy4bFoQeyU"
      },
      "source": [
        "#===========================================#\n",
        "# Importing data\n",
        "#===========================================#\n",
        "\n",
        "heart = pd.read_csv('heart_statlog/heart.csv', sep = ' ', header = None)\n",
        "y = heart.iloc[:,:-1]\n",
        "labels = heart.iloc[:,-1]\n",
        "labels = np.where(labels == 1, 0, labels)\n",
        "labels = np.where(labels == 2, 1, labels)\n",
        "\n",
        "y = y.infer_objects()\n",
        "numobs = len(y)\n",
        "\n",
        "# Too many zeros for this \"continuous variable\". Add a little noise to avoid \n",
        "# the correlation matrix for each group to blow up\n",
        "uniform_draws = uniform(0, 1E-12, numobs)\n",
        "y.iloc[:, 9] = np.where(y[9] == 0, uniform_draws, y[9])\n",
        "\n",
        "n_clusters = len(np.unique(labels))\n",
        "p = y.shape[1]\n",
        "\n",
        "#===========================================#\n",
        "# Formating the data\n",
        "#===========================================#\n",
        "var_distrib = np.array(['continuous', 'bernoulli', 'categorical', 'continuous',\\\n",
        "                        'continuous', 'bernoulli', 'categorical', 'continuous',\\\n",
        "                        'bernoulli', 'continuous', 'ordinal', 'ordinal',\\\n",
        "                        'categorical']) # Last one is ordinal for me (but real\n",
        "                        # real in the data description)\n",
        "    \n",
        "# Ordinal data already encoded\n",
        " \n",
        "y_categ_non_enc = deepcopy(y)\n",
        "vd_categ_non_enc = deepcopy(var_distrib)\n",
        "\n",
        "# Encode categorical datas\n",
        "#y, var_distrib = gen_categ_as_bin_dataset(y, var_distrib)\n",
        "\n",
        "#######################################################\n",
        "# Test to encode categorical variables\n",
        "le = LabelEncoder()\n",
        "for col_idx, colname in enumerate(y.columns):\n",
        "    if var_distrib[col_idx] == 'categorical': \n",
        "        y[colname] = le.fit_transform(y[colname])\n",
        "\n",
        "#################################################\n",
        "\n",
        "# Encode binary data\n",
        "le = LabelEncoder()\n",
        "for col_idx, colname in enumerate(y.columns):\n",
        "    if var_distrib[col_idx] == 'bernoulli': \n",
        "        y[colname] = le.fit_transform(y[colname])\n",
        "    \n",
        "enc = OneHotEncoder(sparse = False, drop = 'first')\n",
        "labels_oh = enc.fit_transform(np.array(labels).reshape(-1,1)).flatten()\n",
        "\n",
        "nj, nj_bin, nj_ord, nj_categ = compute_nj(y, var_distrib)\n",
        "y_np = y.values\n",
        "nb_cont = np.sum(var_distrib == 'continuous')\n",
        "\n",
        "p_new = y.shape[1]\n",
        "\n",
        "\n",
        "# Feature category (cf)\n",
        "cf_non_enc = np.logical_or(vd_categ_non_enc == 'categorical', vd_categ_non_enc == 'bernoulli')\n",
        "\n",
        "# Non encoded version of the dataset:\n",
        "y_nenc_typed = y_categ_non_enc.astype(np.object)\n",
        "y_np_nenc = y_nenc_typed.values\n",
        "\n",
        "# Defining distances over the non encoded features\n",
        "dm = gower_matrix(y_nenc_typed, cat_features = cf_non_enc) \n",
        "\n",
        "dtype = {y.columns[j]: np.float64 if (var_distrib[j] != 'bernoulli') and \\\n",
        "        (var_distrib[j] != 'categorical') else np.str for j in range(p_new)}\n",
        "\n",
        "y = y.astype(dtype, copy=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa7MYZRPXv8L"
      },
      "source": [
        "# MDGMM. \n",
        "import matplotlib as mpl\n",
        "\n",
        "backend_ =  mpl.get_backend() \n",
        "mpl.use(\"Agg\")  # Prevents from showing the plots to gain space\n",
        "\n",
        "# First: automatically find the best architecture \n",
        "r = np.array([5, 4, 3])\n",
        "numobs = len(y)\n",
        "k = [4, n_clusters]\n",
        "eps = 1E-05\n",
        "it = 3\n",
        "maxstep = 100\n",
        "\n",
        "prince_init = dim_reduce_init(y, n_clusters, k, r, nj, var_distrib, seed = None, use_famd = True)\n",
        "out = M1DGMM(y_np, n_clusters, r, k, prince_init, var_distrib, nj, it, eps, maxstep, seed = None)\n",
        "\n",
        "\n",
        "# Then run the best architecture 30 times\n",
        "r = out['best_r']\n",
        "numobs = len(y)\n",
        "k = out['best_k']\n",
        "eps = 1E-05\n",
        "it = 30\n",
        "maxstep = 100\n",
        "\n",
        "\n",
        "nb_trials= 30\n",
        "m1dgmm_res = pd.DataFrame(columns = ['it_id', 'micro', 'macro', 'silhouette'])\n",
        "\n",
        "for i in range(nb_trials):\n",
        "    prince_init = dim_reduce_init(y, n_clusters, k, r, nj, var_distrib, seed = None,\\\n",
        "                                  use_famd = True)\n",
        "\n",
        "    out = M1DGMM(y_np, n_clusters, r, k, prince_init, var_distrib, nj, it,\\\n",
        "                  eps, maxstep, seed = None, perform_selec = False)\n",
        "    m, pred = misc(labels_oh, out['classes'], True) \n",
        "    try:\n",
        "      sil = silhouette_score(dm, pred, metric = 'precomputed')\n",
        "    except:\n",
        "      sil = -1\n",
        "    micro = precision_score(labels_oh, pred, average = 'micro')\n",
        "    macro = precision_score(labels_oh, pred, average = 'macro')\n",
        "    print(micro)\n",
        "    print(macro)\n",
        "\n",
        "    m1dgmm_res = m1dgmm_res.append({'it_id': i + 1, 'micro': micro, 'macro': macro, \\\n",
        "                                'silhouette': sil}, ignore_index=True)\n",
        "\n",
        "\n",
        "mpl.use(backend_) # Reset backend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgAH-9RwcZ7I",
        "outputId": "dbcae781-7a20-49b1-b59c-f2ca077b182d"
      },
      "source": [
        "print(m1dgmm_res.mean())\r\n",
        "print(m1dgmm_res.std())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it_id         15.500000\n",
            "micro          0.825185\n",
            "macro          0.824007\n",
            "silhouette     0.254065\n",
            "dtype: float64\n",
            "it_id         8.803408\n",
            "micro         0.011928\n",
            "macro         0.012497\n",
            "silhouette    0.002808\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfBJgkLdUtRj"
      },
      "source": [
        "## PIMA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH_teudFWkfm"
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/MDGMM_suite/datasets')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95ncE0gxUknP"
      },
      "source": [
        "pima = pd.read_csv('pima/pima_indians.csv', sep = ',')\n",
        "y = pima.iloc[:,:-1]\n",
        "labels = pima.iloc[:,-1]\n",
        "\n",
        "y = y.infer_objects()\n",
        "numobs = len(y)\n",
        "\n",
        "\n",
        "n_clusters = len(np.unique(labels))\n",
        "p = y.shape[1]\n",
        "\n",
        "#===========================================#\n",
        "# Formating the data\n",
        "#===========================================#\n",
        "var_distrib = np.array(['ordinal', 'continuous', 'continuous', 'continuous',\\\n",
        "                        'continuous', 'continuous', 'continuous', 'continuous']) \n",
        " \n",
        "# Ordinal data already encoded\n",
        " \n",
        "y_categ_non_enc = deepcopy(y)\n",
        "vd_categ_non_enc = deepcopy(var_distrib)\n",
        "\n",
        "# No categ data\n",
        "# No binary data \n",
        "\n",
        "enc = OneHotEncoder(sparse = False, drop = 'first')\n",
        "labels_oh = enc.fit_transform(np.array(labels).reshape(-1,1)).flatten()\n",
        "\n",
        "nj, nj_bin, nj_ord, n_categ = compute_nj(y, var_distrib)\n",
        "y_np = y.values\n",
        "nb_cont = np.sum(var_distrib == 'continuous')\n",
        "\n",
        "p_new = y.shape[1]\n",
        "\n",
        "# Feature category (cf)\n",
        "cf_non_enc = np.logical_or(vd_categ_non_enc == 'categorical', vd_categ_non_enc == 'bernoulli')\n",
        "\n",
        "# Non encoded version of the dataset:\n",
        "y_nenc_typed = y_categ_non_enc.astype(np.object)\n",
        "y_np_nenc = y_nenc_typed.values\n",
        "\n",
        "# Defining distances over the non encoded features\n",
        "dm = gower_matrix(y_nenc_typed, cat_features = cf_non_enc) \n",
        "\n",
        "\n",
        "dtype = {y.columns[j]: np.float64 if (var_distrib[j] != 'bernoulli') and \\\n",
        "        (var_distrib[j] != 'categorical') else np.str for j in range(p_new)}\n",
        "dtype['Pregnancies'] = np.str\n",
        "\n",
        "y = y.astype(dtype, copy=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTz7wHwJUwAZ"
      },
      "source": [
        "import matplotlib as mpl\n",
        "\n",
        "backend_ =  mpl.get_backend() \n",
        "mpl.use(\"Agg\")  # Prevents from showing the plots to gain space\n",
        "\n",
        "# First: automatically find the best architecture \n",
        "r = np.array([5, 4, 3])\n",
        "numobs = len(y)\n",
        "k = [4, n_clusters]\n",
        "eps = 1E-05\n",
        "it = 2\n",
        "maxstep = 100\n",
        "\n",
        "prince_init = dim_reduce_init(y, n_clusters, k, r, nj, var_distrib, seed = None,\\\n",
        "                              use_famd = True)\n",
        "out = M1DGMM(y_np, n_clusters, r, k, prince_init, var_distrib, nj, it, eps,\\\n",
        "             maxstep, seed = None)\n",
        "\n",
        "# Then run the best architecture 30 times\n",
        "r = out['best_r']\n",
        "numobs = len(y)\n",
        "k = out['best_k']\n",
        "eps = 1E-05\n",
        "it = 30\n",
        "maxstep = 100\n",
        "\n",
        "nb_trials= 30\n",
        "m1dgmm_res = pd.DataFrame(columns = ['it_id', 'micro', 'macro', 'silhouette'])\n",
        "\n",
        "for i in range(nb_trials):\n",
        "    prince_init = dim_reduce_init(y, n_clusters, k, r, nj, var_distrib, seed = None,\\\n",
        "                                  use_famd = True)\n",
        "    \n",
        "    out = M1DGMM(y_np, n_clusters, r, k, prince_init, var_distrib, nj, it,\\\n",
        "                  eps, maxstep, seed = None, perform_selec = False)\n",
        "    m, pred = misc(labels_oh, out['classes'], True) \n",
        "\n",
        "    try:\n",
        "      sil = silhouette_score(dm, pred, metric = 'precomputed')\n",
        "    except:\n",
        "      sil = -1\n",
        "    micro = precision_score(labels_oh, pred, average = 'micro')\n",
        "    macro = precision_score(labels_oh, pred, average = 'macro')\n",
        "\n",
        "    m1dgmm_res = m1dgmm_res.append({'it_id': i + 1, 'micro': micro, 'macro': macro, \\\n",
        "                                'silhouette': sil}, ignore_index=True)\n",
        "\n",
        "\n",
        "mpl.use(backend_) # Reset backend\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYpxlYU4c9sw",
        "outputId": "8ce26aea-a2f6-4347-daa9-31e430ca6314"
      },
      "source": [
        "print(m1dgmm_res.mean())\r\n",
        "print(m1dgmm_res.std())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it_id         15.500000\n",
            "micro          0.641189\n",
            "macro          0.616231\n",
            "silhouette     0.230101\n",
            "dtype: float64\n",
            "it_id         8.803408\n",
            "micro         0.024794\n",
            "macro         0.020724\n",
            "silhouette    0.016014\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}